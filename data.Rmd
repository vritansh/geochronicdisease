

```{r}

#data = read.csv(file = 'CDC.csv') 

#df <- data[data$YearStart %in% c('2018', '2019', '2020','2021'), ]

#drop <- c("X")
#df = df[,!(names(df) %in% drop)]

#tidydf <- df %>% 
#  rownames_to_column("id") %>% 
#  gather(key, value, -id) %>% 
#  mutate(missing = ifelse(is.na(value), "yes", "no"))

#dat2 <- read.csv("CDC.csv", header=T, na.strings=c("","NA"))
#sapply(dat2, function(x) sum(is.na(x)))
#df <- dat2[dat2$YearStart %in% c('2018', '2019', '2020','2021'), ]
#missing.values <- df %>%
#  gather(key = "key", value = "val") %>%
#  mutate(is.missing = is.na(val)) %>%
#  group_by(key, is.missing) %>%
#  summarise(num.missing = n()) %>%
#  filter(is.missing==T) %>%
#  select(-is.missing) %>%
#  arrange(desc(num.missing)) 
```
```{r}
#ggplot() + geom_bar(data = missing.values, aes(x=key, y=num.missing), stat = 'identity')+labs(x='variable', y="number of missing values", title='Number of missing values') + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + coord_cartesian(ylim=c(0,100000)) + scale_y_continuous(breaks=seq(0,100000,12500))
```
```{r}
#library(redav)
#plot_missing(dat2, percent = FALSE)
```
```{r}
#row.plot <- df %>%
#  mutate(id = row_number()) %>%
#  gather(-id, key = "key", value = "val") %>%
#  mutate(isna = is.na(val)) %>%
#  ggplot(aes(key, id, fill = isna)) +
#    geom_raster(alpha=0.8) +
#    scale_fill_manual(name = "",
#        values = c('steelblue', 'tomato3'),
#        labels = c("Present", "Missing")) +
#    scale_x_discrete(limits = levels) +
#    labs(x = "Variable",
#           y = "Row Number", title = "Missing values in rows") +
#    coord_flip()

#row.plot
```
```{r}
#df  %>%
#  summarise_all(list(~is.na(.)))%>%
#  pivot_longer(everything(),
#               names_to = "variables", values_to="missing")

#df  %>%
#  summarise_all(list(~is.na(.)))%>%
#  pivot_longer(everything(),
#      names_to = "variables", values_to="missing") %>%
#  count(variables, missing)

#df  %>%
#  summarise_all(list(~is.na(.)))%>%
#  pivot_longer(everything(),
#        names_to = "variables", values_to="missing") %>%
#  count(variables, missing) %>%
#  ggplot(aes(y=variables,x=n,fill=missing))+
#  geom_col()
```



# Data

## Sources

The dataset used in this project is borrowed from the division of population health in <b>Center for Disease Control and Prevention (CDC)</b> - (https://catalog.data.gov/dataset/u-s-chronic-disease-indicators-cdi). 
The dataset was created on 10th November 2020 and was last modified on 21st April 2022.

```{r}
library(dplyr)
library(ggplot2)
library(forcats)
library(tidyr)
library(tibble)
library(choroplethr)
library(tidyverse)
library(mapview)
```

It contains 1082328 entries, where there are 34 attributes contributing to the observance of the chronic disease in the United States of America.

    ```{r}
    data <- read.csv("ChronicDiseases.csv")
    dim(data)
    ```

Let's have a look at the structure of the dataset in order to comprehend the varied traits that help define the data. 

```{r}
str(data)
```

The attributes that we focus on for this project are:

<li>YearStart : Year in which the chronic disease was recorded.</li> 
<li>LocationAbbr : State associated with the chronic disease.</li> 
<li>DataSource : Contributors for the survey conducted to record the chronic diseases.</li> 
<li>Topic : Name of the chronic disease.</li> 
<li>Question : Indicators associated with a chronic disease, for example - Mortality, Binge Consumption, etc,.</li> 
<li>DataValue : Population that have been affected by a specific indicator.</li> 
<li>Stratification1 : Describes the gender or race of an individual.</li> 
<li>GeoLocation : The latitude and longitude points at which the data was collected.</li>  

</br>
We observe that there are several redundant columns and multiple columns with null values. Since we can't work directly with this dataset, we analyze the missing values and then transform the data into it's usable form.

## Missing value analysis

We need to check whether the data has NA values or in some cases just a null string.

```{r}
NA_count <- colSums(is.na(data))
NA_count
```

--- one plot to 100% missing values ---

it is clear that the columns - "Response", "DataValueAlt", "LowConfidenceLimit", "HighConfidenceLimit", "StratificationCategory2", "Stratification2", "StratificationCategory3", "Stratification3", "ResponseID", 


------ Add Ritvik's Code --------

## Cleaning / transformation

Based on the analysis from the plots above, we will be dropping 16 features (mentioned above) that have missing values since it makes more sense than imputing those columns.

```{r}
    data <-dplyr::select(data, -c('StratificationCategoryID2', 'StratificationCategoryID3','StratificationID2','StratificationID3', 'StratificationCategory2','Stratification2','StratificationCategory3','Stratification3', 'LowConfidenceLimit','Response', 'HighConfidenceLimit','ResponseID','DataValueUnit','DataValueAlt','DataValueFootnoteSymbol', 'DatavalueFootnote'))
    str(data)
```

To be more specific on a period of data, we will be trimming the dataset down to the "Pre-During COVID" period i,e 2018 - 2020 to estimate the effect of chronic diseases on the individuals.


    ```{r}
    data <- data[data$YearStart %in% c('2018', '2019', '2020'), ]
    ```

Since there are many categories in the Data Value type, we will extract entries related to "Number" that give us the population count.

    ```{r}
    data <- data[data$DataValueType %in% c("Number"), ]
    ```

    ```{r}
    data$DataValue[data$DataValue==""] <- 0
    data$DataValue <- as.numeric(data$DataValue)
    str(data)
    ```


There are 8 data sources contributing to the collection of chronic data after pre-processing the data,(intially there were 26 contributors). 

    ```{r}
    length(unique(data$DataSource))
    ```

    ```{r}
    data %>%
      group_by(DataSource) %>%
      summarise(count = n()) %>%
      ggplot(aes(x=fct_reorder(DataSource, count,.desc = FALSE),y=count)) +
      geom_bar(stat = "identity",fill = "orange") +
      ggtitle("DataSource Distribution") +
      coord_flip()+
      xlab("DataSource") + 
      theme(panel.grid.major.x = element_blank())

    ```

From the plot, it is clear that "NVSS" has most contributions, we will be using the data only from that source for our analysis. 

    ```{r}
    data <- data[data$DataSource %in% c("NVSS"), ]
    dim(data)
    str(data)
    ```

The updated data after cleaning and considering the optimal attributes has 10540 entries and 18 attributes that constitutes our primary 8 featurese along with 10 supporting features for analysis.

